#!/bin/bash
#
# cnode_smoketest -- a simpler script to smoketest performance on a cluster using
# the existing VAST cnodes. because of the contention, and also lack of RDMA
# from the base OS, this internal test will show at most 80 or 90% of the
# true potential of real-world testing from outside the cluster and NFSoRDMA
#
# rmallory  rob@vastdata.com
#           Wed Jan  8 22:16:18 EST 2020 -- @buffalo beef on weck tweaks
#           Fri Jan 10 22:32:48 UTC 2020 -- @san soho, total rewrrite
#           Fri Jan 24 00:24:46 UTC 2020 -- @sko , confirmation from alon about ISL
#           Mon Jan 27 18:48:47 UTC 2020 -- added andys interface prefs static routes
#           Sat Apr 18 16:02:49 UTC 2020 -- added a second ${mntpt}_2 to get max BW
#
# we use directio to not fill up the buffercache and give storage perspective stats
# Notes: currently, half of the procs run at half-rate. suspect numa or ISL overload (fixed)
#        this script should scale nicely out to a 12x12 system or larger.
#

#  The below variables make a combination which fits your application
#IOSIZE=32k
IOSIZE=1m

NUMJOBS=8
#NUMJOBS=4
#NUMJOBS=8

# you normally run just one..  and with VIPOFFSET=0 it will only mount iteself.
# if you crank it up to 1 2 3 4 like below , then it
# that will mount the subsequent cnodes vips and you can go for max-bandwidth
# but in that case you should DO_ROUTES=true  to keep off the ISL
#LOOPS="1 2 3 4"
#LOOPS="1 2 3"
LOOPS="1 2"
#LOOPS="1"

IODEPTH=8
#IODEPTH=12

SIZE=10g
#SIZE=1g
# Instead of size based, lets run time based.
#RUNTIME="--runtime=45s"
#RUNTIME="--runtime=4m"

# This needs to be set to true if VIPOFFSET > 0  else half the traffic goes across ISL as seen with:  show interfaces port-channel
DO_ROUTES=true
DO_ROUTES=false

### This lets you chose to loopback mount the current cnode, or the next one up to exercise the network
### 0 means loopback mount my own vips
VIPOFFSET=0
#VIPOFFSET=1

## Don't change any variables below.

VIPS=/tmp/vips.$$
U=$VIPS
mVIP=`cat /vast/vman/mgmt-vip`
test -r $HOME/.ssh/admin_pass.txt || echo "you need to put the admin password in $HOME/.ssh/admin_pass.txt or in this script"
test -r $HOME/.ssh/admin_pass.txt || exit
ADMINPASS=$(cat $HOME/.ssh/admin_pass.txt)

### Go get the vip list
/usr/bin/curl -s -u admin:${ADMINPASS} -H "accept: application/json" --insecure -X GET "https://$mVIP/api/vips/"  | grep -Po '(?<="id").*(?=cluster)' | sed 's/"id"//g' | sed 's/},{/\n/g'  | grep -Po '(?<="vippool").*(?=cnode)' | cut -d\" -f2 | sort -u > ${VIPS}_long
if [ "$(wc -l ${VIPS}_long | awk '{print $1}')" -gt 1 ]
then
     echo "Found more than one vippool:  $(cat ${VIPS}_long | tr '\n' ' ')"
     echo "Choosing the first one: $(head -1 ${VIPS}_long)" ;

     /usr/bin/curl -s -u admin:${ADMINPASS} -H "accept: application/json" --insecure -X GET "https://$mVIP/api/vips/"  | grep -Po '(?<="id").*(?=cluster)' | sed 's/"id"//g' | sed 's/},{/\n/g' | grep $(head -1 ${VIPS}_long) | awk -F, '{print $6 $8}' | awk -F\" '{print $4" " $8}' | grep -v '^.$' > ${VIPS}
set +x
else
/usr/bin/curl -s -u admin:${ADMINPASS} -H "accept: application/json" --insecure -X GET "https://$mVIP/api/vips/"  | grep -Po '(?<="id").*(?=cluster)' | sed 's/"id"//g' | sed 's/},{/\n/g' | awk -F, '{print $6 $8}' | awk -F\" '{print $4" " $8}' | grep -v '^.$' > ${VIPS}
fi

# pools
#https://$mVIP/api/vips/?vippool__id=${POOL}

### Figure out how many vips per cnode there are
cat ${VIPS} | tr '-' ' ' | sort -n -k3

NUM=$(wc -l ${VIPS}| awk '{print $1}')
FIRST=$(head -1 $VIPS | awk '{print $NF}')
PER=$(grep $FIRST $VIPS  | wc -l | awk '{print $1}')
CNODES=$(($NUM / $PER))
echo "Found: $CNODES  Cnodes with $PER ip addrs each"

ALL_CNODES=$(clush -g cnodes uname -n  2>&1 | awk '{print $1}' | tr -d : | cut -d. -f4 | sort -n |tr '\n' ' ')

echo VIPS=$VIPS
sleep 2

##########################################################
############ Setup the static route if needed (from andy)
#an attempt to try and temporarily setup the routing table to ensure that reads/writes go over both ifaces.
#It aboslutely improves TPUT on a large system, else half will be using the IPL ports
#
#first, figure out what ifaces we need to use.
export EXT_IFACES=$(cat /etc/vast-configure_network.py-params.ini|grep external|awk -F "=" {'print $2'}| sed -E 's/,/ /')
# we only care if there are more than one iface.
export iface_count=`echo $EXT_IFACES | wc -w`

###if you really want to use this logic, change the `3` to a `2` on the next line, and also in the route deletion block at the end of this script.
if [ $iface_count -eq 2  -a "$DO_ROUTES" = "true" ] ; then
  #so...this gets complicated.  sometimes the route is OK, sometimes its not, so we have to check them all and only change if they are 'wrong'
  for iface in $EXT_IFACES
    do IPS_TO_ROUTE=$(clush -g cnodes "/sbin/ip a s ${iface} | grep vip|egrep -o '[0-9]{1,3}*\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}'"|awk {'print $2'})
    #now that we have them all, check what the route looks like on this node for each ip.
    for IP in ${IPS_TO_ROUTE}
      do current_route=`/sbin/ip route get ${IP}|egrep -o 'dev \w+'|awk {'print $2'}`
      if [[ ${current_route} == $iface ]] ; then
        echo "route is OK for $IP -> $iface , skipping"
      else
        echo "fixing route for $IP -> $iface"
        clush -g cnodes sudo /sbin/ip route add ${IP}/32 dev ${iface}
        #sudo /sbin/ip route add ${IP}/32 dev ${iface}
      fi
    done
  done
else
  echo "only one external iface, skipping route setup"
fi
#####################################################################
### Main loop

clush -g cnodes '/usr/bin/docker ps -q --filter label=role=vms' > /tmp/vms_is_here
VMSHOST=$(cat /tmp/vms_is_here | cut -d: -f1)
echo FOUND VMS RUNNING ON $VMSHOST
echo FOUND VMS RUNNING ON $VMSHOST

echo done audit
sleep 10

#######  done audit     #############################################

# Hmm.. when mounting other cnodes, even us and them same time, tput goes down.
# so we just mount our local vips and we seem to get max perf.
for TWO in $LOOPS
do
echo
for ((x=1;x<$((CNODES+2));x+=1))
do
# here we pick the mounts from this cnode, or the next cnode, or next..
  y=$((x+VIPOFFSET))
  if [ $y -gt $((CNODES+2)) ] ; then y=1 ; fi
  itsvips=$(grep "cnode-${y}$" ${VIPS} | awk '{print $1}' | tr '\n' ' ')
  z=1

  for i in $itsvips
    do


# Setup the mount and then run fio in one ssh
      mntpt=/mnt/cnode${y}/$z
      now_epoch=$(date +%s)
      now_long=$(date)
      my_hostname=$(uname -n)


### Bail out if we are trying to run on the VMS host.
if [ "$CNODES" -ge 12 ]
then
#echo "CHECKING if $VMSHOST = 172.16.3.$x"
    if [ "$VMSHOST" = "172.16.3.$x" ]
    then echo "WARN:  Continuing on.. Not testing on VMS host"
         continue
    fi
fi

### then run the benchmark .. two mounts to my same vip.
echo "Launching 172.16.3.$x $i $mntpt   "

ssh 172.16.3.$x "sudo umount $mntpt >/dev/null 2>&1 ; test -d $mntpt || sudo mkdir -p $mntpt ;sudo mount -o soft,nolock $i:/ $mntpt ;sleep 1 ; mkdir -p $mntpt/${x}/${z} ; (cd $mntpt/${x}/${z} ; echo "starting hostname=$my_hostname  pwd=$mntpt/${x}/${z} mountpoint=$i:/  start_epoch=\$\(date +%s\) " > myfio_out.$$ ; df -t nfs -k $mntpt/${x}/${z}  && nohup /usr/bin/fio --name=rand --ioengine=libaio --fallocate=none --iodepth=$IODEPTH --rw=randrw --bs=$IOSIZE --size=$SIZE  --refill_buffers --randrepeat=0 --numa_mem_policy=local $CPUFLAGS --direct=1 $RUNTIME --numjobs=$NUMJOBS --rwmixread=100 --group_reporting | tee -a myfio_out.$$ & )" &
ssh 172.16.3.$x "sudo umount ${mntpt}_2 >/dev/null 2>&1 ; test -d ${mntpt}_2 || sudo mkdir -p ${mntpt}_2 ;sudo mount -o soft,nolock $i:/ ${mntpt}_2 ;sleep 1 ; mkdir -p ${mntpt}_2/${x}/${z}_2 ; (cd ${mntpt}_2/${x}/${z}_2 ; echo "starting hostname=$my_hostname  pwd=${mntpt}_2/${x}/${z}_2 mountpoint=$i:/  start_epoch=\$\(date +%s\) " > myfio_out.$$ ; df -t nfs -k ${mntpt}_2/${x}/${z}_2  && nohup /usr/bin/fio --name=rand --ioengine=libaio --fallocate=none --iodepth=$IODEPTH --rw=randrw --bs=$IOSIZE --size=$SIZE --refill_buffers --randrepeat=0 --numa_mem_policy=local $CPUFLAGS --direct=1 $RUNTIME --numjobs=$NUMJOBS --rwmixread=100 --group_reporting | tee -a myfio_out.$$ & )" &

      set +x
#writes
#/usr/bin/fio --name=rand --ioengine=libaio --fallocate=none --iodepth=16 --rw=randrw --bs=1mb --create_on_open=1 --refill_buffers --randrepeat=0 --direct=1 --size=10g --numjobs=8 --rwmixread=0 --group_reporting

  z=$((z+1))
    done
done
VIPOFFSET=$((VIPOFFSET+1))
done
sleep 2

echo
echo
echo '###########################'

clush -g cnodes df -t nfs

echo '###########################'

wait

#####################################################################
echo "---------------------------------------------"
echo "Done testing.. now collecting stats"
echo "---------------------------------------------"

### Run stats on them

MYID=$(ifconfig -a 2>/dev/null | grep 172.16.3 | awk '{print $2}' | cut -d. -f4)
cnodes=$(cat ${VIPS} | awk '{print $2}' | cut -d- -f2 | sort -un | tr '\n' ' ')
#for x in $(ifconfig -a 2>/dev/null | grep 172.16.3 | awk '{print $2}' | cut -d. -f4) $cnodes

#STATS_MOUNT=$(df -t nfs | tail -1 | awk '{print $NF}')
#
#for num_cnode in $(seq 1 $CNODES)
#do
#for mounts_per in $(seq 1 $PER)
#do
#      mntpt=$STATS_MOUNT/$num_cnode/$mounts_per
#      myfile=$(ls -lrt $mntpt/myfio_* | tail -1 | awk '{print $NF}')
#
#      test -f $myfile || continue
#      mytput=$(grep READ $myfile | awk '{print $3}' | sed -e 's/.*(\(.*\))/\1/' -e 's/MB\/s,//'  )
#      wallclock=$(grep READ $myfile | awk '{print $NF}' | sed -e 's/run=.*-\(.*\)$/\1/')
#      start_epoch=$(grep start_epoch $myfile  | grep -oP   'start_epoch=([0-9])*' | cut -d= -f2)
#      end_epoch=$(date +%s)
#      if [ -n "$start_epoch" ]
#          then runtime=$(($end_epoch-$start_epoch))
#          echo "$(uname -n) mntpt=$mntpt start_epoch=$start_epoch end_epoch=$end_epoch runtime=$wallclock tput=${mytput} MB/s date=$(date)"
#      fi
#done
#done

# audit after
rm -f /tmp/arp_en /tmp/ifconfig_a
clush -g cnodes "/usr/sbin/arp -en" > /tmp/arp_en
clush -g cnodes "/usr/sbin/ifconfig -a" > /tmp/ifconfig_a


### Now be sure to unmount all NFS mounts from teh cnodes.

echo "---------------------------------------------"
echo "Unmounting NFS mounts"
echo "---------------------------------------------"
set -x

clush -g cnodes 'sudo umount -t nfs -a'
STILL=/tmp/still_mounted.$$
clush -g cnodes 'df -t nfs 2>&1' 2>&1 | grep 'mnt/cnode' > $STILL
for i in $(cat $STILL | awk '{print $1}')
  do ssh $i sudo umount -t nfs -a
done

STILLMORE=/tmp/stillmore_mounted.$$
clush -g cnodes 'df -t nfs 2>&1' 2>&1 | grep 'mnt/cnode' > $STILLMORE
for i in $(cat $STILLMORE | awk '{print $1}')
  do echo ssh $i sudo umount -t nfs -a
          ssh $i sudo umount -t nfs -a
done
set +x

echo "---------------------------------------------"
echo "Removing any static routes setup by this test"
echo "---------------------------------------------"
#####  Another block from Andy..
#get rid of routes...change the `3` to `2` if you used the routing affinity.
if [ $iface_count -eq 2  -a "$DO_ROUTES" = "true" ] ; then
  for iface in $EXT_IFACES
    do export IPS_TO_ROUTE=$(clush -g cnodes "/sbin/ip a s ${iface} | grep vip|egrep -o '[0-9]{1,3}*\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}'"|awk {'print $2'})
    for IP in ${IPS_TO_ROUTE}
    # a little heavy handed, but its OK.
      do   echo "+ clush -g cnodes sudo /sbin/ip route del ${IP}/32 dev ${iface}"
                clush -g cnodes sudo /sbin/ip route del ${IP}/32 dev ${iface} 2>&1 | egrep -v 'No such process|exited with exit code 2'
    done
  done
else
  echo "only one external iface, skipping route destruction"
fi

#### Doing post processing.. gotta make a mount on this host.
mount -o soft,nolock $i:/ /smoketest_stats
